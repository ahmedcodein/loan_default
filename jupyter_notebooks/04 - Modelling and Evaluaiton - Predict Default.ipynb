{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# **Modelling and Evaluation - Predict Default (Classification)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "*   Fit and evaluate a classification model to predict if a debt applicant will default or not.\n",
    "*   Answer **business requirement 2**: \n",
    "    * The client is interested in creating a classification model able to predict loan applicant default event with high confidence with high precision of at least 85%. \n",
    "\n",
    "## Inputs\n",
    "\n",
    "* outputs/datasets/collection/row/LoanDefaultDataset.csv\n",
    "* Instructions on which variables to use for data cleaning and feature engineering. Those instructions are found in FeatureEngineering Notebook.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* The following is a list of files to be saved in the output folder:\n",
    "\n",
    "  - Train Set\n",
    "  - Test Set\n",
    "  - Modeling pipeline\n",
    "  - label map\n",
    "  - feature importance plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SetUp**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from feature_engine import transformation as vt\n",
    "from sklearn.metrics import make_scorer, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqP-UeN-z3i2"
   },
   "source": [
    "### Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOGIGS-uz3i2"
   },
   "source": [
    "* Change the working directory from its current folder to its parent folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZfF_j-Bz3i4",
    "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
   },
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MWW8E7lz3i7"
   },
   "source": [
    "* Make the parent of the current directory the new current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TwHsQRWjz3i9",
    "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
   },
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_xPk_Ijz3i-"
   },
   "source": [
    "* Confirm the new current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vz3S-_kjz3jA",
    "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
   },
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dataset Loading**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the row dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (pd.read_csv(\"outputs/datasets/collection/row/LoanDefaultDataset.csv\"))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ML Pipeline with All Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Split Train and Test Set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the row dataset into Train and Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['loan_status'], axis=1),\n",
    "    df['loan_status'],\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Cleaning and Feature Engineering Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning\n",
    "\n",
    "- Since the data is already clean, this step is skipped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering Pipeline\n",
    "\n",
    "- The feature engineering pipeline is extracted from **Notebook 03**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PipelineFeatureEngineering():\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
    "                                                     variables=[\n",
    "                                                        'person_gender',\n",
    "                                                        'person_education',\n",
    "                                                        'person_home_ownership',\n",
    "                                                        'loan_intent',\n",
    "                                                        'previous_loan_defaults_on_file',\n",
    "                                                        ])),\n",
    "        (\"YeoJohnsonTransformer\", vt.YeoJohnsonTransformer(\n",
    "            variables = [\n",
    "                'person_income',\n",
    "                'loan_amnt',\n",
    "                'loan_percent_income',\n",
    "                'credit_score',\n",
    "                ])),\n",
    "\n",
    "        (\"SmartCorrelatedSelection\", SmartCorrelatedSelection(variables=None,\n",
    "         method=\"spearman\", threshold=0.7, selection_method=\"variance\")), # to be dropped = ['person_age', 'cb_person_cred_hist_length'].\n",
    "    ])\n",
    "\n",
    "    return pipeline_base\n",
    "\n",
    "\n",
    "PipelineFeatureEngineering()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply Feature Engineering Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pipeline_feat_eng = PipelineFeatureEngineering()\n",
    "X_train = pipeline_feat_eng.fit_transform(X_train)\n",
    "X_test = pipeline_feat_eng.transform(X_test)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Target Balance Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display Train Set Target (loan_status) distribution.\n",
    "- Evaluate if the two loan_status classes (Default = 0, No Default = 1) are balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Result:\n",
    "\n",
    "- The default class (0) has more occurrences, hence the train set ought to be balanced.\n",
    "- In order to balance both classes in the Train Set, SMOTE (Synthetic Minority Oversampling TEchnique) is used. \n",
    "- This is accomplished by oversampling the minority class (No Default = 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply **SMOTE (Synthetic Minority Oversampling TEchnique)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE(sampling_strategy='minority', random_state=0)\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate the Train Set Target distribution after oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ML Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the main functions and Dictionaries for creating the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PipelineClf(model):\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"feat_selection\", SelectFromModel(model)),\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "\n",
    "    return pipeline_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Hyperparameter Optimization Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperparameterOptimizationSearch:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "\n",
    "            model = PipelineClf(self.models[key])\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, )\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "        columns = ['estimator', 'min_score',\n",
    "                   'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "        return df[columns], self.grid_searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define a dictionary for estimators with standard hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_quick_search = {\n",
    "    \"LogisticRegression\": LogisticRegression(random_state=0),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=0),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(random_state=0),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=0),\n",
    "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=0),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=0),\n",
    "}\n",
    "\n",
    "params_quick_search = {\n",
    "    \"LogisticRegression\": {},\n",
    "    \"DecisionTreeClassifier\": {},\n",
    "    \"RandomForestClassifier\": {},\n",
    "    \"GradientBoostingClassifier\": {},\n",
    "    \"ExtraTreesClassifier\": {},\n",
    "    \"AdaBoostClassifier\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimator Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate estimators performance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
    "search.fit(X_train, y_train,\n",
    "           scoring =  make_scorer(recall_score, pos_label=0),\n",
    "           n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Summarize estimators performance scores result.\n",
    "* Display the scores' results in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Result:\n",
    "\n",
    "* The best performing estimators are list below by order:\n",
    "  * **ExtraTreesClassifier** with mean score of **0.922684**\n",
    "  * **DecisionTreeClassifier** with mean score of **0.913894**\n",
    "  * **RandomForestClassifier** with mean score of **0.911572**\n",
    "* **Important Note**:\n",
    "  * when implementing **ExtraTreesClassifier** pipeline_clf pickle file becomes extremely large (> 100 MB, which is not compatible with GitHub max storage). Therefore, the **RandomForestClassifier** is used as an Alternative. \n",
    "* The next step aims to search for the hyperparameter configurations seeking better estimator scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define the best Estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[2,0] # Select the third best model\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Search Hyperparameter Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define a dictionary for the best estimator: **RandomForestClassifier**.\n",
    "* Define a dictionary for candidate hyperparameter configurations of each nominated estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_search = {\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(random_state=0),\n",
    "}\n",
    "params_search = {\n",
    "    \"RandomForestClassifier\":{'model__n_estimators': [100,50,140],\n",
    "                             'model__max_depth': [None,4, 15],\n",
    "                             'model__min_samples_split': [2,50],\n",
    "                             'model__min_samples_leaf': [1,50],\n",
    "                             'model__max_leaf_nodes': [None,50],\n",
    "                            },\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apply HyperparameterOptimizationSearch on candidate estimators with the candidate parameter configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train,\n",
    "           scoring =  make_scorer(recall_score, pos_label=0),\n",
    "           n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Summarize the configurations score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Display the best hyperparameters configuration for **ExtraTreesClassifier**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = grid_search_pipelines[best_model].best_params_\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Result:\n",
    "- The estimator performance improves by optimizing the hyperparameter.\n",
    "- The mean score with optimized hyperparameter is 0.911822. No significant improvement over the default configuration.\n",
    "- best_parameters = `{'model__max_depth': None,\n",
    " 'model__max_leaf_nodes': None,\n",
    " 'model__min_samples_leaf': 1,\n",
    " 'model__min_samples_split': 2,\n",
    " 'model__n_estimators': 50}`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define the best clf pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_clf = grid_search_pipelines[best_model].best_estimator_\n",
    "pipeline_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_and_report(X, y, pipeline, label_map):\n",
    "\n",
    "    prediction = pipeline.predict(X)\n",
    "\n",
    "    print('---  Confusion Matrix  ---')\n",
    "    print(pd.DataFrame(confusion_matrix(y_true=prediction, y_pred=y),\n",
    "          columns=[[\"Actual \" + sub for sub in label_map]],\n",
    "          index=[[\"Prediction \" + sub for sub in label_map]]\n",
    "          ))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print('---  Classification Report  ---')\n",
    "    print(classification_report(y, prediction, target_names=label_map), \"\\n\")\n",
    "\n",
    "\n",
    "def clf_performance(X_train, y_train, X_test, y_test, pipeline, label_map):\n",
    "    print(\"#### Train Set #### \\n\")\n",
    "    confusion_matrix_and_report(X_train, y_train, pipeline, label_map)\n",
    "\n",
    "    print(\"#### Test Set ####\\n\")\n",
    "    confusion_matrix_and_report(X_test, y_test, pipeline, label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Business Requirement 2**:\n",
    "  - Default event should be predicted with high confidence, specifically, at least 85% precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_performance(X_train=X_train, y_train=y_train,\n",
    "                X_test=X_test, y_test=y_test,\n",
    "                pipeline=pipeline_clf,\n",
    "                label_map= ['Default','No Default']\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Result:\n",
    "\n",
    "* for test set:\n",
    "\n",
    "  - Default Precision: 0.95\n",
    "  - Default Recall: 0.91\n",
    "  - No Default Precision: 0.74\n",
    "  - No Default Recall: 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Assess feature importance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extract the important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    'Feature': X_train.columns[pipeline_clf['feat_selection'].get_support()],\n",
    "    'Importance': pipeline_clf['model'].feature_importances_})\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    ")\n",
    "\n",
    "# re-assign best_features order\n",
    "best_features = df_feature_importance['Feature'].to_list()\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Result:\n",
    "- best_features = `['previous_loan_defaults_on_file', 'loan_percent_income', 'loan_int_rate', 'person_income']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Summary of **ML Pipeline with All Features**:\n",
    "\n",
    "- * **RandomForestClassifier** proved to be the most effective estimator which also produces smaller clf_pipeline pickle file in comparsion with other two candidates. The estimator is defined with a configuration: `{'model__max_depth': None,\n",
    " 'model__max_leaf_nodes': [None],\n",
    " 'model__min_samples_leaf': [1],\n",
    " 'model__min_samples_split': [2],\n",
    " 'model__n_estimators': [50]\n",
    "}`.\n",
    "* The model performs extremely well on the full features pipeline both on the train and test dataset.\n",
    "* The model suffices the business requirement 2 with higher precision than what business stipulates.\n",
    "* An assessment is conducted to identify the most important features.\n",
    "* Three features are assessed to be important. These are: `['previous_loan_defaults_on_file', 'loan_percent_income', 'loan_int_rate', 'person_income']`.\n",
    "* The next step is to evaluate the ML pipeline on the most important features only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ML Pipeline with Important Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display Best Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Result:\n",
    "- best_features = `['previous_loan_defaults_on_file',\n",
    " 'loan_percent_income',\n",
    " 'loan_int_rate',\n",
    " 'person_income']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Split Train and Test Set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the row dataset into Train and Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['loan_status'], axis=1),\n",
    "    df['loan_status'],\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Consider only the best features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.filter(best_features)\n",
    "X_test = X_test.filter(best_features)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Cleaning and Feature Engineering Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning\n",
    "\n",
    "- Since the data is already clean, this step is skipped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering Pipeline\n",
    "\n",
    "- The feature engineering pipeline is extracted from **Notebook 03** with employing the best features instead.\n",
    "- Since the dataset now does not contain the to-be-dropped features ['person_age', 'cb_person_cred_hist_length'], SmartCorrelatedSelection is dropped from the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PipelineFeatureEngineering():\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
    "                                                     variables=[\n",
    "                                                        'previous_loan_defaults_on_file',\n",
    "                                                        ])),\n",
    "        (\"YeoJohnsonTransformer\", vt.YeoJohnsonTransformer(\n",
    "            variables = ['loan_percent_income','person_income',]\n",
    "            )),\n",
    "        # SmartCorrelatedSelection is removed since we filter out all the unneeded features\n",
    "        # by only selecting the important features.\n",
    "    ])\n",
    "\n",
    "    return pipeline_base\n",
    "\n",
    "PipelineFeatureEngineering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply Data Feature Engineering Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_feat_eng = PipelineFeatureEngineering()\n",
    "X_train = pipeline_feat_eng.fit_transform(X_train)\n",
    "X_test =pipeline_feat_eng.transform(X_test)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Target Balance Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display Train Set Target (loan_status) distribution.\n",
    "- Evaluate if the two loan_status classes (Default = 0, No Default = 1) are balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Result:\n",
    "\n",
    "- The default class (0) has more occurrences, hence the train set ought to be balanced.\n",
    "- In order to balance both classes in the Train Set, SMOTE (Synthetic Minority Oversampling TEchnique) is used. \n",
    "- This is accomplished by oversampling the minority class (No Default = 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply **SMOTE (Synthetic Minority Oversampling TEchnique)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE(sampling_strategy='minority', random_state=0)\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate the Train Set Target distribution after oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PipelineClf(model):\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "\n",
    "    return pipeline_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The best model and its hyperparameter configuration extracted from the earlier task are:\n",
    "  - Estimator : **RandomForestClassifier**.\n",
    "  - Hyperparameter Configuration: `{'model__max_depth': None,\n",
    " 'model__max_leaf_nodes': None,\n",
    " 'model__min_samples_leaf': 1,\n",
    " 'model__min_samples_split': 2,\n",
    " 'model__n_estimators': 140}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_search # RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = {'RandomForestClassifier': RandomForestClassifier(random_state=0)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the best hyperparameter configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define a new search parameters based on the best configurations identified in the earlier step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_search = {'RandomForestClassifier': {\n",
    "    'model__max_depth': [None],\n",
    "    'model__max_leaf_nodes': [None],\n",
    "    'model__min_samples_leaf': [1],\n",
    "    'model__min_samples_split': [2],\n",
    "    'model__n_estimators': [50]\n",
    "},\n",
    "}\n",
    "params_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply the the Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_search = HyperparameterOptimizationSearch(\n",
    "    models=best_model, params=params_search)\n",
    "quick_search.fit(X_train, y_train,\n",
    "                 scoring=make_scorer(recall_score, pos_label=0),\n",
    "                 n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the algorithm score result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = quick_search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note:\n",
    "- The estimator performance is slightly better after refitting the model on the significant features. \n",
    "- The mean score with all the features is 0.911.\n",
    "- The mean score with the significant features is 0.915967."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[0, 0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = {'model__max_depth': [None],\n",
    " 'model__max_leaf_nodes': [None],\n",
    " 'model__min_samples_leaf': [1],\n",
    " 'model__min_samples_split': [2],\n",
    " 'model__n_estimators': [50]}\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define and then display the best clf pipline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_clf = grid_search_pipelines[best_model].best_estimator_\n",
    "pipeline_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Pipeline on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_performance(X_train=X_train, y_train=y_train,\n",
    "                X_test=X_test, y_test=y_test,\n",
    "                pipeline=pipeline_clf,\n",
    "                label_map= ['Default', 'No Default'] \n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Result:\n",
    "\n",
    "* for test set:\n",
    "\n",
    "  - Default Precision: 0.95\n",
    "  - Default Recall: 0.92\n",
    "  - No Default Precision: 0.75\n",
    "  - No Default Recall: 0.83"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Summary of **ML Pipeline with Best Features**:\n",
    "\n",
    "* **RandomForestClassifier** proved to be the most effective estimator with a configuration: `{'model__max_depth': [None],\n",
    " 'model__max_leaf_nodes': [None],\n",
    " 'model__min_samples_leaf': [1],\n",
    " 'model__min_samples_split': [2],\n",
    " 'model__n_estimators': [50]}`.\n",
    "* The model performance sustain it performance on the important feature pipeline with even a slight improvement.\n",
    "* The model suffices the business requirement 2 with higher precision than what business stipulates.\n",
    "* Four features are assessed to be important. These are: best_features = `['previous_loan_defaults_on_file', 'loan_percent_income', 'loan_int_rate', 'person_income']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Assess feature importance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extract the important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = X_train.columns\n",
    "\n",
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    'Feature': best_features,\n",
    "    'Importance': pipeline_clf['model'].feature_importances_})\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    ")\n",
    "\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Result:\n",
    "- The result affirms that are no additional filtration has occurred to the input features of the pipeline.\n",
    "- best_features = `['previous_loan_defaults_on_file', 'loan_percent_income', 'loan_int_rate', 'person_income']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Push files to Repo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following list summarize the Notebook's generated outputs:\n",
    "  - Train Set\n",
    "  - Test Set\n",
    "  - Modeling pipeline\n",
    "  - label map\n",
    "  - feature importance plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v1'\n",
    "file_path = f'outputs/ml_pipeline/predict_default/{version}'\n",
    "\n",
    "try:\n",
    "  os.makedirs(name=file_path)\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the train set (features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save the train set (features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(f\"{file_path}/X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the train set (target='loan_status')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save the train set (target='loan_status')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the Test set (features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save the Test set (features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(f\"{file_path}/X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the Test set (target='loan_status')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save the Test set (target='loan_status')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note:\n",
    "\n",
    "- Since the row data is already cleaned there is no data clean pipeline to be saved or incorporated into the feature engineering pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the Feature Engineering Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_feat_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save the Feature Engineering Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=pipeline_feat_eng ,\n",
    "            filename=f\"{file_path}/clf_pipeline_feat_eng.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display Feature Scaling and Model pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save the Model Pipeline as a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=pipeline_clf, filename=f\"{file_path}/clf_pipeline_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate clf_pipeline_model.pkl file size before git commit and push.\n",
    "- If the file size > 100Mb repeat the search to find the most efficient estimator both in terms of score and model size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pipeline_model_file_path = \"outputs/ml_pipeline/predict_default/v1/clf_pipeline_model.pkl\"\n",
    "file_size_bytes = os.path.getsize(clf_pipeline_model_file_path)\n",
    "print(\"File size in bytes:\", file_size_bytes)\n",
    "\n",
    "file_size_mb = file_size_bytes/(1024 * 1024)\n",
    "print(\"File size in MB:\", round(file_size_mb, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Result:\n",
    "\n",
    "File size in MB: 27.4 when using RandomForestClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display feature importance plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save feature importance plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance.plot(kind='bar',x='Feature',y='Importance')\n",
    "plt.savefig(f'{file_path}/features_importance.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "\n",
    "> **ML Pipeline with Best Features**:\n",
    "\n",
    "* ML Pipeline with best features performed quite well in comparison with all features.\n",
    "* **RandomForestClassifier** proved to be the most effective estimator with a configuration: `{'model__max_depth': [None],\n",
    " 'model__max_leaf_nodes': [None],\n",
    " 'model__min_samples_leaf': [1],\n",
    " 'model__min_samples_split': [2],\n",
    " 'model__n_estimators': [50]}`.\n",
    "* The model performance sustain it performance on the important feature pipeline with even a slight improvement.\n",
    "* The model suffices the business requirement 2 with higher precision than what business stipulates.\n",
    "* Four features are assessed to be important. These are: best_features = `['previous_loan_defaults_on_file', 'loan_percent_income', 'loan_int_rate', 'person_income']`."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "*   Answer **business requirement 1**: \n",
        "    * The client is interested to extract hidden relationship patterns among the variables in loan default dataset, so the client can learn the most relevant variables that can affect default event.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/datasets/loan_data.csv.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate code that answers business requirement 1 and can be used to build the Streamlit App.\n",
        "* whenever applicable, evaluate the validity of the aforementioned hypotheses.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "## **Change working directory**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "* Change the working directory from its current folder to its parent folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "* Make the parent of the current directory the new current directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "* Confirm the new current directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Dataset Loading**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = (pd.read_csv(\"outputs/datasets/collection/row/LoanDefaultDataset.csv\"))\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Data Exploration**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Get the YData Profiling Report.\n",
        "* Observe variable types and any potential transformation are needed. \n",
        "* Observer an missing cells in any of the variables in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "pandas_report = ProfileReport(df=df, minimal=True)\n",
        "pandas_report.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Result:\n",
        "\n",
        "- Variable Types:\n",
        "  - 9 Numeric.\n",
        "  - 5 Text (Categorical - Object).\n",
        "- No Missing Cells.\n",
        "- The Target variable **loan_status** is unbalanced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Correlation Study**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Implement OneHotEncoder class to perform categorical feature transformation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.encoding import OneHotEncoder\n",
        "encoder = OneHotEncoder(variables=df.columns[df.dtypes=='object'].to_list(), drop_last=False)\n",
        "df_ohe = encoder.fit_transform(df)\n",
        "print(df_ohe.shape)\n",
        "df_ohe.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ppscore as pps\n",
        "\n",
        "\n",
        "def heatmap_corr(df, threshold, figsize=(20, 12), font_annot=8):\n",
        "    if len(df.columns) > 1:\n",
        "        mask = np.zeros_like(df, dtype=bool)\n",
        "        mask[np.triu_indices_from(mask)] = True\n",
        "        mask[abs(df) < threshold] = True\n",
        "\n",
        "        fig, axes = plt.subplots(figsize=figsize)\n",
        "        sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                    mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
        "                    linewidth=0.5\n",
        "                    )\n",
        "        axes.set_yticklabels(df.columns, rotation=0)\n",
        "        plt.ylim(len(df.columns), 0)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def heatmap_pps(df, threshold, figsize=(20, 12), font_annot=8):\n",
        "    if len(df.columns) > 1:\n",
        "        mask = np.zeros_like(df, dtype=bool)\n",
        "        mask[abs(df) < threshold] = True\n",
        "        fig, ax = plt.subplots(figsize=figsize)\n",
        "        ax = sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                         mask=mask, cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
        "                         linewidth=0.05, linecolor='grey')\n",
        "        plt.ylim(len(df.columns), 0)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "    df_corr_spearman = df.corr(method=\"spearman\", numeric_only=True)\n",
        "    df_corr_pearson = df.corr(method=\"pearson\", numeric_only=True)\n",
        "\n",
        "    pps_matrix_raw = pps.matrix(df)\n",
        "    pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "    pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "    print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
        "    print(pps_score_stats.round(3))\n",
        "\n",
        "    return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix, CorrThreshold, PPS_Threshold,\n",
        "                      figsize=(20, 12), font_annot=8):\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"* Analyse how the target variable for your ML models are correlated with other variables (features and target)\")\n",
        "    print(\"* Analyse multi-colinearity, that is, how the features are correlated among themselves\")\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "    print(\"It evaluates monotonic relationship \\n\")\n",
        "    heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "    print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "    heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
        "    print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
        "          f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
        "    heatmap_pps(df=pps_matrix, threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df_ohe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
        "                  df_corr_spearman = df_corr_spearman, \n",
        "                  pps_matrix = pps_matrix,\n",
        "                  CorrThreshold = 0.2, PPS_Threshold =0.1,\n",
        "                  figsize=(12,8), font_annot=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Implement Spearman and Pearson correlation methods respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_pearson = df_corr_pearson['loan_status'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
        "corr_spearman = df_corr_spearman['loan_status'].sort_values(key=abs, ascending=False)[1:].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Extract the top five strongest correlation levels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_n = 5\n",
        "set(corr_pearson[:top_n].index.to_list() + corr_spearman[:top_n].index.to_list())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Create a list out of the titles of the qualified features for further investigation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars_to_study = ['loan_int_rate','loan_percent_income', 'person_home_ownership','person_income', 'previous_loan_defaults_on_file']\n",
        "vars_to_study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Implementation of EDA on selected variables**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Create an Exploratory Data list out of the qualified features for further investigation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_eda = df.filter(vars_to_study + ['loan_status'])\n",
        "df_eda.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Variables Distribution against Loan Status**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "  * Evaluate important feature distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "\n",
        "def plot_categorical(df, col, target_var):\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    sns.countplot(data=df, x=col, hue=target_var, order=df[col].value_counts().index)\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.title(f\"{col}\", fontsize=20, y=1.05)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_numerical(df, col, target_var):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.histplot(data=df, x=col, hue=target_var, kde=True, element=\"step\")\n",
        "    plt.title(f\"{col}\", fontsize=20, y=1.05)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "target_var = 'loan_status'\n",
        "for col in vars_to_study:\n",
        "    if df_eda[col].dtype == 'object':\n",
        "        plot_categorical(df_eda, col, target_var)\n",
        "        print(\"\\n\\n\")\n",
        "    else:\n",
        "        plot_numerical(df_eda, col, target_var)\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Parallel Plot**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Extract the max and min values of loan interest rate to create a rate map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_eda.info()\n",
        "print(\"-----\")\n",
        "max_interest_rate = df_eda['loan_int_rate'].max()\n",
        "min_interest_rate = df_eda['loan_int_rate'].min()\n",
        "print(\"The maximum interest rate:\", max_interest_rate)\n",
        "print(\"The minimum interest rate:\", min_interest_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.discretisation import ArbitraryDiscretiser\n",
        "import numpy as np\n",
        "rate_map = [-np.Inf, 5, 7.5, 10, 12.5, 15, 17.5, 20, np.Inf]\n",
        "disc = ArbitraryDiscretiser(binning_dict={'loan_int_rate': rate_map})\n",
        "df_parallel = disc.fit_transform(df_eda)\n",
        "df_parallel.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "disc.binner_dict_['loan_int_rate']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_classes = len(rate_map) - 1\n",
        "classes_ranges = disc.binner_dict_['loan_int_rate'][1:-1]\n",
        "\n",
        "labels_map = {}\n",
        "for n in range(0, n_classes):\n",
        "    if n == 0:\n",
        "        labels_map[n] = f\"<{classes_ranges[0]}\"\n",
        "    elif n == n_classes-1:\n",
        "        labels_map[n] = f\"+{classes_ranges[-1]}\"\n",
        "    else:\n",
        "        labels_map[n] = f\"{classes_ranges[n-1]} to {classes_ranges[n]}\"\n",
        "\n",
        "labels_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_parallel['loan_int_rate'] = df_parallel['loan_int_rate'].replace(labels_map)\n",
        "df_parallel.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "fig = px.parallel_categories(df_parallel, color=\"loan_status\")\n",
        "fig.show(renderer='jupyterlab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusions\n",
        "\n",
        "From the correlation study the following conclusions are extracted:\n",
        "\n",
        "* Pervious loan default has positive and moderate correlation to loan approval.\n",
        "* Loan-to-income ratio has positive and weak correlation to loan approval.\n",
        "* Interest Rate has positive and weak correlation to loan approval.\n",
        "* Home ownership has weak correlation to loan approval. This correlation exercises two duality depending on home ownership status (i.e. rent, own and mortgage)\n",
        "* Income has negative and very weak correlation to loan approval."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
